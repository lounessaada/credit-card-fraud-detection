# ğŸ’³ Credit Card Fraud Detection (Machine Learning)

## ğŸ¯ Objectif du projet
Ce projet vise Ã  prÃ©parer un dataset propre, transformÃ© et Ã©quilibrÃ© afin dâ€™entraÃ®ner un modÃ¨le de Machine Learning capable de dÃ©tecter des transactions bancaires frauduleuses.

Le contexte est celui de la fraude bancaire europÃ©enne, un phÃ©nomÃ¨ne rare mais coÃ»teux, oÃ¹ :
- les fraudes non dÃ©tectÃ©es (FN) entraÃ®nent des pertes financiÃ¨res importantes,
- les fausses alertes (FP) gÃ©nÃ¨rent des coÃ»ts opÃ©rationnels Ã©levÃ©s.

## ğŸ“Š Description du dataset
- Nombre de lignes : 284 807
- Nombre de variables : 31
- Variable cible : `Class`
  - 0 : transaction normale
  - 1 : transaction frauduleuse
- Variables :
  - V1 Ã  V28 : variables issues dâ€™une PCA
  - Amount : montant de la transaction
  - Time : temps en secondes

La fraude reprÃ©sente environ **0,17 %** des transactions, ce qui rend le dataset fortement dÃ©sÃ©quilibrÃ©.

## âš ï¸ ProblÃ©matique et mÃ©triques
Lâ€™accuracy nâ€™est pas pertinente dans ce contexte.
Les mÃ©triques adaptÃ©es sont :
- **ROC-AUC**
- **PR-AUC (mÃ©trique prioritaire)**, centrÃ©e sur la classe rare (fraude)

## ğŸ” Analyse exploratoire (EDA)
- `Amount` est asymÃ©trique et contient des outliers.
- Les fraudes se concentrent souvent sur :
  - de trÃ¨s petits montants (transactions de test),
  - de trÃ¨s grands montants.
- Analyse par dÃ©ciles de `Amount` : distribution en **forme de U** du risque de fraude.
- Extraction de lâ€™heure depuis la variable `Time`.

## ğŸ§ª SÃ©paration Train / Test (anti data leakage)
- Split effectuÃ© avant toute transformation.
- Split stratifiÃ© pour conserver le mÃªme taux de fraude.
- Objectif : Ã©viter toute fuite dâ€™information.

## ğŸ”§ Transformations appliquÃ©es
- `log1p(Amount)` pour rÃ©duire lâ€™asymÃ©trie
- `RobustScaler` pour gÃ©rer les outliers
- Transformation de Yeo-Johnson sur certaines variables V*

## ğŸ§  Feature engineering (logique mÃ©tier)
- `Hour` : heure extraite depuis `Time`
- `is_very_small_amount` : Amount < Q10
- `is_very_large_amount` : Amount > Q90

Les seuils Q10 et Q90 sont calculÃ©s uniquement sur le jeu dâ€™entraÃ®nement.

## âš–ï¸ Gestion du dÃ©sÃ©quilibre des classes
MÃ©thodes testÃ©es :
- Baseline (sans rÃ©Ã©chantillonnage)
- `class_weight='balanced'`
- Random UnderSampling
- SMOTE

## ğŸ“ˆ RÃ©sultats
La mÃ©trique principale retenue est la **PR-AUC**.

- Baseline : PR-AUC â‰ˆ 0.74 (bonne prÃ©cision, recall plus faible)
- SMOTE : PR-AUC â‰ˆ 0.73 (recall Ã©levÃ©, nÃ©cessite ajustement du seuil)
- UnderSampling : PR-AUC â‰ˆ 0.62 (performance dÃ©gradÃ©e)

## ğŸšï¸ Ajustement du seuil
- Seuil par dÃ©faut (0.5) â†’ trop de faux positifs
- Seuil optimisÃ© : **0.95**
- RÃ©sultat : forte rÃ©duction des faux positifs tout en conservant un recall Ã©levÃ© (~0.89)

## âœ… Validation finale
- Dataset final prÃªt pour le Machine Learning
- 33 variables finales
- Train : 227 845 lignes
- Test : 56 962 lignes

## ğŸ Conclusion
Ce projet respecte les bonnes pratiques du Machine Learning :
- prÃ©vention du data leakage,
- transformations adaptÃ©es,
- mÃ©triques pertinentes pour un dataset dÃ©sÃ©quilibrÃ©.

Il montre que, dans un contexte de fraude bancaire, la **PR-AUC** et lâ€™**ajustement du seuil** sont essentiels pour obtenir un modÃ¨le exploitable mÃ©tier.

## ğŸ‘¥ Auteurs
- Yazid Aloui  
- Yanis Hanouti  
- Lounes Saada  
- Omar El Mejdoubi El Imam  

